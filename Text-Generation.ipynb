{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Markov chains can be used for very basic text generation. Think about every word as a state. We can make a simple assumption that the next word is only dependent on the previous word - which is the basic assumption of a Markov chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the text\n",
    "with open('songs.txt', 'r') as file:\n",
    "    data = file.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a Markov Chain Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to build a simple Markov chain function that creates a dictionary:\n",
    "* The keys should be all of the words in the corpus\n",
    "* The values should be a list of the words that follow the keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def markov_chain(text):\n",
    "    '''The input is a string of text and the output will be a dictionary with each word as\n",
    "       a key and each value as the list of words that come after the key in the text.'''\n",
    "    \n",
    "    # Tokenize the text by word, though including punctuation\n",
    "    text = text.split(' ')\n",
    "    words = [item.replace('\\n', ' ') for item in text]\n",
    "    \n",
    "    # Initialize a default dictionary to hold all of the words and next words\n",
    "    m_dict = defaultdict(list)\n",
    "    \n",
    "    # Create a zipped list of all of the word pairs and put them in word: list of next words format\n",
    "    for current_word, next_word in zip(words[0:-1], words[1:]):\n",
    "        m_dict[current_word].append(next_word)\n",
    "\n",
    "    # Convert the default dict back into a dictionary\n",
    "    m_dict = dict(m_dict)\n",
    "    return m_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dictionary for Ali's routine, take a look at it\n",
    "nirvana_dict = markov_chain(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Text Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to create a function that generates sentences. It will take two things as inputs:\n",
    "* The dictionary you just created\n",
    "* The number of words you want generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def generate_sentence(chain, count=15):\n",
    "    '''Input a dictionary in the format of key = current word, value = list of next words\n",
    "       along with the number of words you would like to see in your generated sentence.'''\n",
    "\n",
    "    # Capitalize the first word\n",
    "    word1 = random.choice(list(chain.keys()))\n",
    "    sentence = word1.capitalize()\n",
    "\n",
    "    # Generate the second word from the value list. Set the new word as the first word. Repeat.\n",
    "    for i in range(count-1):\n",
    "        word2 = random.choice(chain[word1])\n",
    "        word1 = word2\n",
    "        sentence += ' ' + word2\n",
    "\n",
    "    # End it with a period\n",
    "    sentence += '.'\n",
    "    return(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hear a new complaint Forever in the blame Aqua sea foam shame Sunburn freezer burn Choking on door clangs,.\n",
      "In floyd observes my head And I'm dumb    Sell the ashes of salt Everything is gone, but I feel.\n",
      "When I shaved my head I'm so are you Broke our mirrors Sunday morning is broke, but I.\n",
      "Fun i think I'm really scared Floyd breathes hard, I could eat your heart-shaped box for this.\n",
      "In floyd observes my candles in my head I'm so ugly, that's okay, 'cause today I care And.\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(generate_sentence(nirvana_dict))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
